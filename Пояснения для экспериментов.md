Работа в Airflow  
Выполняемый DAG-файл [stock_forecast.py](https://github.com/sosdatpapku/mlops4/blob/main/airflow_dags) выполняет следующие задачи:  
1. Получение данных (Запускает скрипт Python get_data.py)  
2. Подготовка данных (Запускает скрипт Python preprocess_data.py)  
3. Разделение данных на обучающую и тестовую выборки (Запускает скрипт Python train_test_split.py)  
4. Обучение модели машинного обучения (Запускает скрипт Python train_model.py)  
5. Тестирование модели машинного обучения (Запускает скрипт Python test_model.py)  

Работа в MLFlow  
1) [get_data.py](https://github.com/sosdatpapku/mlops4/blob/main/scripts/get_data.py)  
Этот mlflow-эксперимент выполняет задачи по получению данных, записи данных в файл, логированию артефакта  
2) [process_data.py](https://github.com/sosdatpapku/mlops4/blob/main/scripts/process_data.py)  
Этот mlflow-эксперимент выполняет задачи по обработке данных, сохранению обработанных данных в файл, логированию артефакта  
3) [train_model.py](https://github.com/sosdatpapku/mlops4/blob/main/scripts/train_model.py)  
Этот mlflow-эксперимент выполняет задачи по обучению модели прогнозирования временных рядов, а также сохранению обученной модели в pickle-файл  
4) [test_model.py](https://github.com/sosdatpapku/mlops4/blob/main/scripts/test_model.py)
Этот mlflow-эксперимент выполняет задачи по оценке производительности обученной модели по метрике MAE и её логированию
